library("tidyverse")
library("janitor")
library("naniar")
sharks <- read_csv("data/SharkIncidents_1950_2022_220302.csv") %>% clean_names()
sharks_test <- read_csv("data/SharkIncidents_1950_2022_220302.csv") %>% clean_names()
summary(sharks)
miss_var_summary(sharks)
sharks <- sharks %>%
filter(incident_num != "NOT COUNTED")
sharks_test %>%
filter(!incident_num=="NOT COUNTED")
sharks %>%
group_by(county) %>%
summarise(n = n()) %>%
ggplot(aes(x=reorder(county, n), y=n)) +
geom_col(fill = "#0099f9", alpha=0.8)+
labs(title="Shark Incidents by County (1950-2022)",
x=NULL,
y="n") +
theme(axis.text.x = element_text(angle = 60, hjust = 1),
plot.title = element_text(size = 14, face="bold"))+
geom_text(aes(label = n), vjust = -0.2, size = 3, color = "black")
sharks %>%
count(county) %>%
arrange(desc(n))
sharks %>%
group_by(month) %>%
summarise(total=n(), .groups='keep') %>%
ggplot(aes(x=as_factor(month), y=total))+
geom_col(fill = "#0099f9", alpha=0.8)+
labs(title="Shark Incidents by Month",
x="Month",
y="n")+
theme(plot.title = element_text(size = 14, face="bold"))
sharks %>%
tabyl(county, injury) %>%
adorn_totals("col") %>%
arrange(desc(fatal)) %>%
as_tibble()
sharks %>%
group_by(county, injury) %>%
summarise(total=n(), .groups='keep') %>%
pivot_wider(names_from = injury, values_from = total) %>%
mutate(total=sum(minor, major, fatal, none, na.rm=T)) %>%
arrange(desc(fatal))
sharks %>%
count(mode) %>%
arrange(desc(n))
sharks %>%
ggplot(aes(x=injury, fill=injury))+
geom_bar(alpha=0.8, position="dodge")+
facet_wrap(~mode)+
labs(title="Injury Type by Activity",
x=NULL,
y="Number of Incidents")+
theme(strip.text = element_text(size=10),
axis.text.x = element_text(size=8, angle = 60, hjust = 1))
sharks %>%
count(species) %>%
arrange(desc(n))
sharks %>%
filter(species=="White") %>%
ggplot(aes(x=injury))+
geom_bar(fill = "#0099f9", alpha=0.8)+
labs(title="Incidents Involving Great White Sharks",
x="Injury",
y="n")+
theme(axis.text.x = element_text(angle = 60, hjust = 1),
plot.title = element_text(size = 14, face="bold"))
white_sharks <- read_csv("data/White sharks tracked from Southeast Farallon Island, CA, USA, 1999 2004.csv", na = c("?", "n/a")) %>% clean_names()
glimpse(white_sharks)
miss_var_summary(white_sharks)
white_sharks %>%
filter(sex!="NA") %>%
group_by(sex) %>%
summarise(mean_length=mean(total_length_cm, na.rm=T),
n=n(), .groups='keep')
white_sharks %>%
filter(sex!="NA") %>%
ggplot(aes(x=sex, y=total_length_cm, fill=sex))+
geom_boxplot(alpha=0.8)+
labs(title="Length of Great White Sharks by Sex",
x="Sex",
y="Total Length (cm)")
white_sharks %>%
filter(sex!="NA") %>%
ggplot(aes(x=total_length_cm))+
geom_density(fill = "#0099f9", alpha=0.8)+
facet_wrap(~sex)+
labs(title="Distribution of Total Length by Sex",
x="Total Length (cm)",
y=NULL)+
theme(strip.text = element_text(size=10),
axis.text.x = element_text(size=8, angle = 60, hjust = 1))
library("tidyverse")
library("janitor")
library("naniar")
sharks <- read_csv("data/SharkIncidents_1950_2022_220302.csv") %>% clean_names()
str(sharks)
miss_var_summary(sharks)
new_sh <- sharks %>%
mutate(incident_num=na_if(incident_num, "NOT COUNTED"))
new_sh%>%
filter(incident_num != "NA") %>%
count(county, sort=T) %>%
arrange(desc(n))
sharks%>%
filter(incident_num != "NA") %>%
count(county, sort = T) %>%
arrange(desc(n)) %>%
ggplot(aes(x = county, y = n, fill = county))+
geom_col()+
coord_flip()+
labs(title = "California Shark Incidents",
x = "Number of incidents",
y = "County",
fill = "County")
new_sh %>%
filter(incident_num != "NA") %>%
count(month, sort=T) %>%
arrange(desc(n)) %>%
ggplot(aes(x = month, y = n, group= month))+
geom_col()+
labs(title = "California Shark Incidents",
x = "Number of incidents",
y = "Month",
fill = "Month")
new_sh %>%
filter(incident_num != "NA") %>%
count(month, sort=T) %>%
arrange(desc(n))
new_sh %>%
group_by(county) %>%
count(injury) %>%
pivot_wider(names_from = "county",
values_from = "n")
new_sh %>%
filter(injury == "fatal") %>%
group_by(county) %>%
count(injury) %>%
arrange(desc(n))
new_sh%>%
filter(incident_num != "NA") %>%
count(mode, sort=T) %>%
arrange(desc(n))
new_sh %>%
filter(incident_num != "NA") %>%
count(mode, sort=T) %>%
ggplot(aes(x=mode, y=n, fill=mode))+
geom_col()+
facet_wrap(~mode)+
coord_flip()+
labs(title = "Number and types of injuries by activity",
x = "Type of injuries",
y = "Number of Injuries",
fill = "Type of injuries")
new_sh %>%
filter(incident_num != "NA") %>%
count(species) %>%
arrange(desc(n))
new_sh %>%
filter(incident_num != "NA") %>%
filter(species == "White") %>%
group_by(injury) %>%
ggplot(aes(x=injury, fill = injury))+
geom_bar()+
labs(title = "Great White Sharks Injuries",
x = "Type of Injuries",
y = "Injury count",
fill = "Type of Injuries")
white_sharks <- read_csv("data/White sharks tracked from Southeast Farallon Island, CA, USA, 1999 2004.csv", na = c("?", "n/a")) %>% clean_names()
str(white_sharks)
miss_var_summary(white_sharks)
white_sharks %>%
filter(sex !="NA") %>%
group_by(sex) %>%
summarize(avg = mean(total_length_cm, na.rm = T))
white_sharks %>%
filter(sex != "NA") %>%
group_by(sex) %>%
ggplot(aes(x = sex, y = total_length_cm, fill=sex))+
geom_boxplot(na.rm=T)+
labs(title = "Range of length by sex",
x = "Sex",
y = "Total length",
fill = "Sex")
white_sharks %>%
group_by(maturity) %>%
count(maturity) %>%
ggplot(aes(x=maturity, y=n, fill=maturity))+
geom_col()+
labs(title = "Distribution of maturity",
x = "Maturity",
y = "Count")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library("tidyverse")
library("janitor")
library("lubridate") #this will help us manage dates
files <- list.files(path = "data/spiders", pattern = ".csv", full.names = TRUE)
files
spider_list <- lapply(files, read_csv)
spider_list[[3]]
str(spider_list)
str(spider_list[6])
names <- list.files(path = "data/spiders", pattern = ".csv")
names
names_list <- strsplit(names, split = " .csv")
names_list
names_vec <- unlist(names_list)
names_vec
names(spider_list) <- names_vec
names(spider_list)
str(spider_list["Butte"])
spider_list[["Butte"]]
spider_list[["Butte"]]
spiders_all <- bind_rows(spider_list)
spiders_all
table_A <- read_csv("data/table_A.csv")
table_B <- read_csv("data/table_B.csv")
table_A
table_B
#join_type(firstTable, secondTable, by=columnTojoinOn)
join_type(firstTable, secondTable, by=columnTojoinOn)
inner_exampleDF <- inner_join(table_A, table_B, by="customer_ID")
inner_exampleDF
join_type(firstTable, secondTable, by=columnTojoinOn)
left_exampleDF <- left_join(table_A, table_B, by="customer_ID")
left_exampleDF
right_exampleDF <- right_join(table_A, table_B, by="customer_ID")
right_exampleDF
full_exampleDF <- full_join(table_A, table_B, by="customer_ID")
full_exampleDF
anti_exampleDF <- anti_join(table_A, table_B, by="customer_ID")
anti_exampleDF
spiders_locs <- read_csv("data/spiders locations/spiders_locations.csv")
summary(spiders_with_locs)
summary(spiders_with_locs)
spiders_with_locs <-
left_join(spider_all, spiders_locs, by = "Accession")
spiders_with_locs <-
left_join(spider_all, spiders_locs, by = "Accession")
spiders_with_locs <-
left_join(spiders_all, spiders_locs, by = "Accession")
summary(spiders_with_locs)
spiders_with_locs <-
left_join(spiders_all, spiders_locs, by = "Accession")
summary(spiders_with_locs)
#class(spiders_with_locs$Date)
#glimpse(spiders_with_locs)
day <- today()
day
str(day)
datetime <- now()
datetime
#dmy(spiders_with_locs$Date)
dateformat1 <- "20200922"
dateformat2 <- "09-22-2020"
dateformat3 <- "22/09/2020"
dateformat4 <- "09-22-2020 17:00:00"
dateformat5 <- "20200922 170000"
ymd(dateformat1)
ymd(dateformat2)
ymd(dateformat3)
ymd(dataformat2)
ymd(dateformat2)
ymd(dateformat1)
dateformat1 <- "20200922"
dateformat2 <- "09-22-2020"
dateformat3 <- "22/09/2020"
dateformat4 <- "09-22-2020 17:00:00"
dateformat5 <- "20200922 170000"
dateformat1 <- "20200922"
dateformat2 <- "09-22-2020"
dateformat3 <- "22/09/2020"
dateformat4 <- "09-22-2020 17:00:00"
dateformat5 <- "20200922 170000"
ymd(dateformat1)
ymd(dateformat2)
ymd(dateformat2)
ymd(dateformat2)
ymd(dateformat3)
ymd(dateformat3)
ymd(dateformat3)
ymd(dateformat3)
dmy(spiders_with_locs$Date)
dateformat1 <- "20200922"
dateformat2 <- "09-22-2020"
dateformat3 <- "22/09/2020"
dateformat4 <- "09-22-2020 17:00:00"
dateformat5 <- "20200922 170000"
ymd(dateformat1)
ymd(dateformat2)
ymd(dateformat2)
ymd(dateformat3)
mdy_hms(dateformat4)
write.csv(spiders_with_locs, file = "spiders_with_locs.csv", row.names = FALSE)
library(tidyverse)
library(janitor)
#install.packages("ggmap")
library(ggmap)
install.packages("ggmap")
library(ggmap)
install.packages("ggmap")
register_stadiamaps("e77f55a8-a371-44cd-a7dd-6384b4586d64", write = FALSE)
spiders <- read_csv("data/spiders_with_locs.csv")%>% clean_names()
spiders <- spiders %>% filter(latitude<=42)
spiders <- read_csv("data/spiders_with_locs.csv")%>% clean_names()
spiders %>%
select(latitude, longitude) %>%
summary()
lat <- c(34.67, 41.80)
long <- c(-124.1, -115.5)
bbox <- make_bbox(long, lat, f = 0.03) #f is the fraction of the bounding box to add to the range
map1 <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7)
ggmap(map1)
ggmap(map1) +
geom_point(data = spiders, aes(longitude, latitude), size=0.4) +
labs(x= "Longitude", y= "Latitude", title="Spider Locations")
sharks <- read_csv("data/SharkIncidents_1950_2022_220302.csv") %>%
clean_names() %>%
filter(longitude !="NA" & latitude !="NA") %>% # pulling out NA locations
mutate(longitude = as.numeric(longitude)) # converting longitude to numeric
sharks_dups <- sharks %>%
distinct(location, .keep_all = TRUE) # remove duplicate locations, but keep the remaining variables
sharks_dups <- sharks %>%
distinct(location, .keep_all = TRUE) # remove duplicate locations, but keep the remaining variables
ggmap(map1) +
geom_point(data = sharks, aes(longitude, latitude), size=0.4) +
labs(x= "Longitude", y= "Latitude", title="Shark Locations")
map1 <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7)
ggmap(map2)+
geom_point(data = sharks_dups, aes(x=longitude, y=latitude), size= 0.8)
ggmap(map2)+
geom_point(data = sharks_dups, aes(x=longitude, y=latitude), size= 0.8)
ggmap(map2)+
geom_point(data = sharks_dups, aes(x=longitude, y=latitude), size= 0.8)
ggmap(map2)+
geom_point(data = sharks_dups, aes(x=longitude, y=latitude), size= 0.8)
